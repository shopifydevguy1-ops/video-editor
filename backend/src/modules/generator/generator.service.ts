import { Injectable, Logger } from '@nestjs/common';
import { ConfigService } from '@nestjs/config';
import { PrismaService } from '../../prisma/prisma.service';
import { TTSService } from '../tts/tts.service';
import { ProjectsService } from '../projects/projects.service';
import { PexelsService } from '../media/pexels.service';
import { EditorState, Layer, AspectRatio } from '@ai-video-editor/shared';
import axios from 'axios';

interface Scene {
  text: string;
  duration: number;
  visualType: 'stock' | 'image' | 'animated';
  keywords: string[];
}

interface GeneratedScript {
  hook: string;
  mainContent: string[];
  cta: string;
}

@Injectable()
export class GeneratorService {
  private readonly logger = new Logger(GeneratorService.name);
  private readonly openaiApiKey: string;

  constructor(
    private prisma: PrismaService,
    private ttsService: TTSService,
    private projectsService: ProjectsService,
    private pexelsService: PexelsService,
    private configService: ConfigService,
  ) {
    this.openaiApiKey = this.configService.get<string>('OPENAI_API_KEY') || '';
  }

  async generateScript(topic: string): Promise<GeneratedScript> {
    if (!this.openaiApiKey) {
      throw new Error('OpenAI API key not configured');
    }

    try {
      const prompt = `Create a YouTube video script about "${topic}". 
      The script should have:
      1. A hook (first 3-5 seconds, engaging opening)
      2. Main content (3-5 key points, each 10-15 seconds)
      3. A call-to-action (CTA) at the end (5 seconds)
      
      Return the response in JSON format:
      {
        "hook": "hook text here",
        "mainContent": ["point 1", "point 2", "point 3"],
        "cta": "CTA text here"
      }`;

      const response = await axios.post(
        'https://api.openai.com/v1/chat/completions',
        {
          model: 'gpt-4',
          messages: [
            {
              role: 'system',
              content: 'You are a professional YouTube script writer. Create engaging, concise scripts optimized for retention.',
            },
            {
              role: 'user',
              content: prompt,
            },
          ],
          temperature: 0.7,
          max_tokens: 1000,
        },
        {
          headers: {
            Authorization: `Bearer ${this.openaiApiKey}`,
            'Content-Type': 'application/json',
          },
        },
      );

      const content = response.data.choices[0].message.content;
      const script = JSON.parse(content) as GeneratedScript;

      return script;
    } catch (error: any) {
      this.logger.error(`Script generation failed: ${error.message}`, error.stack);
      // Fallback to simple script
      return {
        hook: `Did you know that ${topic}?`,
        mainContent: [
          `Let's explore ${topic} in detail.`,
          `Here are the key things you need to know.`,
          `This is important for understanding ${topic}.`,
        ],
        cta: 'Like and subscribe for more content!',
      };
    }
  }

  async breakIntoScenes(script: GeneratedScript): Promise<Scene[]> {
    const scenes: Scene[] = [];

    // Hook scene
    scenes.push({
      text: script.hook,
      duration: 4, // 4 seconds for hook
      visualType: 'stock',
      keywords: ['attention', 'hook', 'opening'],
    });

    // Main content scenes
    script.mainContent.forEach((point, index) => {
      scenes.push({
        text: point,
        duration: 12, // 12 seconds per point
        visualType: index % 2 === 0 ? 'stock' : 'image',
        keywords: this.extractKeywords(point),
      });
    });

    // CTA scene
    scenes.push({
      text: script.cta,
      duration: 5,
      visualType: 'animated',
      keywords: ['cta', 'subscribe', 'like'],
    });

    return scenes;
  }

  async generateFacelessVideo(
    userId: string,
    topic: string,
    aspectRatio: AspectRatio = '16:9',
  ): Promise<{ projectId: string }> {
    try {
      // 1. Generate script
      this.logger.log(`Generating script for topic: ${topic}`);
      const script = await this.generateScript(topic);

      // 2. Break into scenes
      this.logger.log('Breaking script into scenes');
      const scenes = await this.breakIntoScenes(script);

      // 3. Generate TTS for each scene
      this.logger.log('Generating TTS audio');
      const ttsAudios = await Promise.all(
        scenes.map((scene) =>
          this.ttsService.generateSpeech(
            {
              text: scene.text,
              voiceId: '21m00Tcm4TlvDq8ikWAM', // Default voice
              speed: 1.0,
            },
            userId,
          ),
        ),
      );

      // 4. Create project
      const project = await this.projectsService.create(userId, {
        name: `Auto-generated: ${topic}`,
        description: 'Generated by AI faceless video generator',
        aspectRatio,
      });

      // 5. Build editor state with layers
      const layers: Layer[] = [];
      let currentTime = 0;

      scenes.forEach((scene, index) => {
        const ttsAudio = ttsAudios[index];

        // Add audio layer
        layers.push({
          id: `audio-${index}`,
          type: 'audio',
          name: `Narration ${index + 1}`,
          startTime: currentTime,
          duration: ttsAudio.duration,
          visible: true,
          locked: false,
          opacity: 1,
          zIndex: index,
          mediaId: '',
          src: ttsAudio.audioUrl,
          trimStart: 0,
          trimEnd: 0,
          volume: 1,
        });

        // Add text layer (captions)
        layers.push({
          id: `text-${index}`,
          type: 'text',
          name: `Caption ${index + 1}`,
          startTime: currentTime,
          duration: ttsAudio.duration,
          visible: true,
          locked: false,
          opacity: 1,
          zIndex: index + 100,
          content: scene.text,
          fontFamily: 'Arial',
          fontSize: 48,
          fontWeight: 'bold',
          color: '#ffffff',
          position: { x: 960, y: 900 }, // Center bottom for 1920x1080
          alignment: 'center',
          animation: 'fade',
        });

        // Add video/image layer with stock footage
        const stockVideoUrl = await this.selectStockFootage(
          scene.keywords,
          editorState.resolution,
        );
        
        layers.push({
          id: `visual-${index}`,
          type: scene.visualType === 'image' ? 'image' : 'video',
          name: `Visual ${index + 1}`,
          startTime: currentTime,
          duration: ttsAudio.duration,
          visible: true,
          locked: false,
          opacity: 1,
          zIndex: index - 100,
          mediaId: '',
          src: stockVideoUrl || '', // Stock footage URL from Pexels
          position: { x: 0, y: 0 },
          scale: 1,
          rotation: 0,
        });

        currentTime += ttsAudio.duration;
      });

      // 6. Update project with editor state
      const editorState: EditorState = {
        version: '1.0.0',
        aspectRatio,
        resolution:
          aspectRatio === '16:9'
            ? { width: 1920, height: 1080 }
            : aspectRatio === '9:16'
            ? { width: 1080, height: 1920 }
            : { width: 1080, height: 1080 },
        duration: currentTime,
        fps: 30,
        layers,
        transitions: [],
        captionStyle: {
          fontFamily: 'Arial',
          fontSize: 48,
          fontWeight: 'bold',
          color: '#ffffff',
          position: 'bottom',
          animation: 'fade',
          wordByWord: true,
        },
      };

      await this.projectsService.update(userId, project.id, {
        editorState,
      });

      this.logger.log(`Generated faceless video project: ${project.id}`);

      return { projectId: project.id };
    } catch (error: any) {
      this.logger.error(`Faceless video generation failed: ${error.message}`, error.stack);
      throw new Error(`Failed to generate faceless video: ${error.message}`);
    }
  }

  private extractKeywords(text: string): string[] {
    // Simple keyword extraction - in production, use NLP library
    const words = text
      .toLowerCase()
      .replace(/[^\w\s]/g, '')
      .split(/\s+/)
      .filter((w) => w.length > 3);
    return words.slice(0, 5);
  }

  private async selectStockFootage(
    keywords: string[],
    resolution: { width: number; height: number },
  ): Promise<string | null> {
    try {
      const query = keywords.join(' ');
      const orientation =
        resolution.width > resolution.height
          ? 'landscape'
          : resolution.width < resolution.height
          ? 'portrait'
          : 'square';

      const searchResult = await this.pexelsService.searchVideos(query, {
        perPage: 5,
        orientation: orientation as 'landscape' | 'portrait' | 'square',
        minDuration: 3,
        maxDuration: 30,
      });

      if (searchResult.videos.length > 0) {
        const selectedVideo = searchResult.videos[0];
        const videoUrl = this.pexelsService.selectBestVideoFile(
          selectedVideo,
          resolution.width,
          resolution.height,
        );
        return videoUrl;
      }

      return null;
    } catch (error) {
      this.logger.warn(`Failed to select stock footage: ${error}`);
      return null;
    }
  }
}

